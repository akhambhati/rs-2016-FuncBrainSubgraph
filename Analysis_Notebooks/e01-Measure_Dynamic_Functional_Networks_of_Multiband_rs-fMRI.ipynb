{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Multiband-Resting-State-fMRI-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Multiband Resting-State fMRI</a></div><div class=\"lev2\"><a href=\"#Summary-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Summary</a></div><div class=\"lev2\"><a href=\"#Methodology-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Methodology</a></div><div class=\"lev1\"><a href=\"#Measure-Dynamic-Functional-Connectivity-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Measure Dynamic Functional Connectivity</a></div><div class=\"lev2\"><a href=\"#Initialize-Environment-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Initialize Environment</a></div><div class=\"lev2\"><a href=\"#Generate-List-of-Data-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Generate List of Data</a></div><div class=\"lev2\"><a href=\"#Design-and-Run-DyNe-Pipeline-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Design and Run DyNe Pipeline</a></div><div class=\"lev3\"><a href=\"#Plot-Sample-BOLD-Signal-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Plot Sample BOLD Signal</a></div><div class=\"lev3\"><a href=\"#Generate-Pipe-Definitions-(JSON-Files)-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Generate Pipe Definitions (JSON Files)</a></div><div class=\"lev3\"><a href=\"#Generate-Pipeline-Definitions-(JSON-File)-2.3.3\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>Generate Pipeline Definitions (JSON File)</a></div><div class=\"lev3\"><a href=\"#Run-the-Pipeline-(in-Parallel)-2.3.4\"><span class=\"toc-item-num\">2.3.4&nbsp;&nbsp;</span>Run the Pipeline (in Parallel)</a></div><div class=\"lev2\"><a href=\"#Plot-Adjacency-Matrices-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Plot Adjacency Matrices</a></div><div class=\"lev3\"><a href=\"#Plot-Configuration-Matrix-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Plot Configuration Matrix</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Multiband Resting-State fMRI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Introduction__*\n",
    "\n",
    "  * The brain is a complex organ that manifests a network of interactions, at the finer scale, between neurons and neuron populations, and at the meso-scale, between large functional domains. Over time, the pattern of interactions between brain regions change, describing a dynamic system capable of supporting cognition during tasks and at rest.\n",
    "  \n",
    "  * Recent advances in functional brain imaging make it possible to acquire images from multiple brain slices simultaneously, known as multiband imaging. \n",
    "  \n",
    "  * Multiband imaging improves the sampling frequency of the blood oxygenation level dependant (BOLD) signal from $\\approx$0.5 Hz to $\\approx$2.0 Hz. With faster sampling of the BOLD signal, we are able to examine functional interactions across whole brain at unprecendent temporal resolution.\n",
    "  \n",
    "  * Previous work has indicated that functional associations between low-frequency components of the fMRI signal (0–0.15 Hz) can be attributed to task-related functional connectivity, whereas associations between high-frequency components (0.2–0.4 Hz) cannot. This frequency specificity of task-relevant functional connectivity is likely to be due at least in part to the hemodynamic response function, which might act as a noninvertible bandpass filter on underlying neural activity.\n",
    "  \n",
    "*__References__*\n",
    "  - Pan, Wen-Ju, et al. \"Infraslow LFP correlates to resting-state fMRI BOLD signals.\" Neuroimage 74 (2013): 288-297.\n",
    "  - F. T. Sun, L. M. Miller, and M. D’Esposito, “Measuring interregional functional connectivity using coherence and partial coherence analyses of fMRI data.” Neuroimage 21 (2004): 647–658.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "heading_collapsed": true
   },
   "source": [
    "## Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Multi-Taper Coherence__*\n",
    "\n",
    "  * Multi-Taper methods are designed to limit the leakage of spectral power from other frequency bands into the frequency bands of interest. This is a critical concern when spectral properties of the signal are computed in discrete temporal windows. Different shapes of the temporal window can cause unwanted effects in the Fourier domain.\n",
    "\n",
    "  * The choice of window length and shape impacts the allowable frequency resolution of the signal power spectrum. Slepian sequences, or orthogonal, wave-like eigenfunctions, give the optimal windowing to achieve a spectral bandwidth resolution on the interval $[-W, W]$. To achieve this resolution, multiple sequences are required, such that the optimal number of Slepian sequences, $k\\approx2WT$, where $k$ is the number of Slepian sequences, $2W$ is the desired spectral resolution bandwidth, and $T$ is the duration of the window.\n",
    "  \n",
    "  * Suppose we wanted to estimate dynamic functional connectivity of fMRI in 30 second windows between 0.034 Hz and 0.167 Hz (i.e. a bandwidth resolution of 0.133 Hz), then the time-bandwidth product would be $4.0 = 0.133 Hz * 30 sec$, and the optimal number of tapers would be $2*4.0-1 = 7$.\n",
    "  \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure Dynamic Functional Connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    %reset\n",
    "except:\n",
    "    print 'NOT IPYTHON'\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import scipy.io as io\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "sys.path.append('/Users/akhambhati/Developer/hoth_research/Echobase')\n",
    "import Echobase\n",
    "\n",
    "rcParams = Echobase.Plotting.fig_format.update_rcparams(rcParams)\n",
    "\n",
    "path_CoreData = '/Users/akhambhati/Remotes/CORE.fMRI_multiband.mmattar/restdata'\n",
    "path_PeriphData = '/Users/akhambhati/Remotes/RSRCH.NMF_Subnetworks'\n",
    "path_ExpData = path_PeriphData + '/e01-Dyne_FuncNetw'\n",
    "\n",
    "for path in [path_CoreData, path_PeriphData, path_ExpData]:\n",
    "    if not os.path.exists(path):\n",
    "        print('Path: {}, does not exist'.format(path))\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate List of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subjs = [full_subj_path.split('/')[-1]\n",
    "         for full_subj_path in glob.iglob('{}/Subjects/*'.format(path_CoreData))]\n",
    "\n",
    "subj_ids = {}\n",
    "proc_path = []\n",
    "for subj in subjs:\n",
    "    run_path = '{}/Subjects/{}/*'.format(path_CoreData, subj)\n",
    "\n",
    "    subj_ids[subj] = []\n",
    "    run_ids = {}\n",
    "    for full_run_path in glob.iglob(run_path):\n",
    "        subj_ids[subj].append(full_run_path.split('/')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design and Run DyNe Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Sample BOLD Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "\n",
    "for subj, dates in subj_ids.items():\n",
    "    for date_id in dates:\n",
    "        \n",
    "        # Generate path to the input fMRI clip\n",
    "        proc_item = '{}/Subjects/{}/{}/HOA112.csv'.format(path_CoreData,\n",
    "                                                          subj, date_id)\n",
    "        if not os.path.exists(proc_item):\n",
    "            raise IOError('Procesing item: {}, not found'.format(proc_item))\n",
    "            \n",
    "        df = pd.read_csv(proc_item)\n",
    "        norm_df = (df - df.mean(axis=0)).as_matrix()\n",
    "        norm_df = norm_df / (0.75*np.std(norm_df, axis=0))\n",
    "        \n",
    "        n_samp = df.shape[0]\n",
    "        Fs = 2.0\n",
    "        time = 120\n",
    "        samples = np.arange(0, time*Fs)\n",
    "        \n",
    "        # Construct result figure\n",
    "        plt.figure()\n",
    "        ax = plt.subplot(111)\n",
    "        \n",
    "        ch_subset = np.arange(0, df.shape[1], 8)\n",
    "        for ch in ch_subset:\n",
    "            ax.plot(samples/Fs, ch + norm_df[map(int, samples), ch], color=[66/256., 152/256., 221./256])\n",
    "            #ax.plot(time, ch + norm_df[:, ch]/(0.75*norm_df[:, ch].max()), )\n",
    "            #break\n",
    "\n",
    "        ax.set_ylim([ch_subset.min()-4, ch_subset.max()+4])\n",
    "\n",
    "        # Axis Settings\n",
    "        ax.yaxis.set_ticks_position('left')\n",
    "        ax.xaxis.set_ticks_position('bottom')\n",
    "        ax.set_xticks([0, 30, 60, 90, 120])\n",
    "        ax.set_ylim([ch_subset.min()-6, ch_subset.max()+6])\n",
    "        ax.set_ylabel('Brain Regions')\n",
    "        ax.set_xlabel('Time (sec)')\n",
    "        \n",
    "        plt.savefig('./e01-Figures/BOLD_Signal.svg')\n",
    "        plt.show()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate proc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proc_list = []\n",
    "\n",
    "for subj, dates in subj_ids.items():\n",
    "    for date_id in dates:\n",
    "        \n",
    "        # Generate path to the input fMRI clip\n",
    "        bold_path = '{}/Subjects/{}/{}/HOA112.csv'.format(path_CoreData,\n",
    "                                                          subj, date_id)\n",
    "        adj_path = '{}/Adjacency.{}.{}.npz'.format(path_ExpData,\n",
    "                                                   subj, date_id)\n",
    "        \n",
    "        if not os.path.exists(bold_path):\n",
    "            raise IOError('Procesing item: {}, not found'.format(bold_path))\n",
    "            \n",
    "        proc_list.append({'bold_path': bold_path,\n",
    "                          'adj_path': adj_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Echobase Pipeline for adajcency matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = {'signal': {},\n",
    "          'coherence': {}}\n",
    "\n",
    "# Signal processing\n",
    "params['signal'] = {'fs': 2,\n",
    "                    'win_len': 30.0,\n",
    "                    'win_disp': 30.0}\n",
    "\n",
    "# Coherence measurement\n",
    "params['coherence'] = {'time_band': 2.5,\n",
    "                       'n_taper': 4,\n",
    "                       'cf': [0.034, 0.20]}\n",
    "\n",
    "\n",
    "def measure_coherence(proc_item):\n",
    "    print('\\nProcessing: {}'.format(proc_item['bold_path']))\n",
    "    \n",
    "    # Load the BOLD Signal from CSV\n",
    "    df = np.array(np.genfromtxt(proc_item['bold_path'], delimiter=','),\n",
    "                  dtype=np.float)\n",
    "    \n",
    "    n_sample, n_node = df.shape\n",
    "    \n",
    "    \n",
    "    # Check window size and displacement\n",
    "    n_win_len = int(params['signal']['win_len'] * params['signal']['fs'])\n",
    "    n_win_disp = int(params['signal']['win_disp'] * params['signal']['fs'])\n",
    "    if n_win_len > n_sample:\n",
    "        raise ValueError('win_len cannot be longer than signal duration')\n",
    "    n_wins = int((n_sample - n_win_len) /\n",
    "                 n_win_disp) + 1\n",
    "            \n",
    "    # Initialize a time-varying adjacency matrix\n",
    "    adj_matr = np.zeros((n_wins, n_node, n_node))\n",
    "    \n",
    "    # Iterate over windows\n",
    "    for win_id, idx in enumerate(range(0, n_wins * n_win_disp, n_win_disp)):\n",
    "        win = df[idx:idx+n_win_len, :]\n",
    "        adj_matr[win_id, ...] = Echobase.Network.Functional.coherence.multitaper(win, params['signal']['fs'],\n",
    "                                                                                 **params['coherence'])\n",
    "    \n",
    "    # Save the output\n",
    "    np.savez(proc_item['adj_path'], adj_matr=adj_matr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "parallel_run = True    \n",
    "    \n",
    "if parallel_run:\n",
    "    mp = Pool(6)\n",
    "    mp.map(measure_coherence, proc_list)\n",
    "else:\n",
    "    map(measure_coherence, proc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Adjacency Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get list of Output Files\n",
    "adj_paths = glob.glob('{}/Adjacency.*.npz'.format(path_ExpData))\n",
    "adj_path = np.random.permutation(adj_paths)[0]\n",
    "\n",
    "# Figure\n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "for ix, ii in enumerate([0, 1, -1]):\n",
    "       \n",
    "    df = np.load(adj_path)\n",
    "    data = df['adj_matr'][ix, :, :]\n",
    "    df.close()\n",
    "\n",
    "    plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    mat = ax.matshow(data, cmap='viridis', vmin=0, vmax=1)\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    plt.savefig('./e01-Figures/Sample_Adjacency_{}.svg'.format(ix+1))\n",
    "    plt.show()\n",
    "    plt.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Configuration Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get list of DyNe Output Files\n",
    "dyne_outp = glob.glob(\"{}/*.dyne_output.hdf\".format(path_ExpData))\n",
    "dyne_logs = glob.glob(\"{}/*.dyne_log.csv\".format(path_ExpData))\n",
    "\n",
    "outp, log = np.random.permutation(zip(dyne_outp, dyne_logs))[0]\n",
    "\n",
    "# Figure\n",
    "%matplotlib inline\n",
    "ix = 0\n",
    "for subj, dates in subj_ids.items():\n",
    "    for date_id in dates:\n",
    "        outp = '{}/{}.{}.dyne_output.hdf'.format(path_ExpData, subj, date_id)\n",
    "        log = '{}/{}.{}.dyne_log.csv'.format(path_ExpData, subj, date_id)        \n",
    "    \n",
    "        df_log = pd.read_csv(log, delimiter=',')\n",
    "        pipe_hash = df_log[df_log.PIPE_NAME == 'MTCoh'].DOWNSTREAM_HASH[0]\n",
    "\n",
    "        df_outp = h5py.File(outp, 'r')\n",
    "        data = df_outp[pipe_hash]['data'][...]\n",
    "        df_outp.close()\n",
    "\n",
    "        triu_ix, triu_iy = np.triu_indices(data.shape[1], k=1)\n",
    "        if ix == 0:\n",
    "            cfg_matr = data[:, triu_ix, triu_iy]            \n",
    "        else:\n",
    "            cfg_matr = np.vstack((cfg_matr, data[:, triu_ix, triu_iy]))\n",
    "        ix += 1\n",
    "    break\n",
    "    \n",
    "n_win = cfg_matr.shape[0]\n",
    "n_conn = cfg_matr.shape[1]\n",
    "\n",
    "plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "mat = ax.matshow(cfg_matr.T, aspect=n_win/n_conn, cmap='rainbow', vmin=0, vmax=1)\n",
    "\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.set_xticks(np.linspace(0, 80, 5))\n",
    "ax.set_ylabel('Functional Interactions')\n",
    "ax.set_xlabel('Time Windows')\n",
    "\n",
    "plt.savefig('./e01-Figures/Sample_Configuration_Matrix.svg')\n",
    "plt.show()\n",
    "plt.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:echobase]",
   "language": "python",
   "name": "conda-env-echobase-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_section_display": "none",
   "toc_threshold": 6,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
