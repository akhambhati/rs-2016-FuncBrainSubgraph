{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Initialize-Environment\" data-toc-modified-id=\"Initialize-Environment-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Initialize Environment</a></div><div class=\"lev2 toc-item\"><a href=\"#Generate-List-of-Data\" data-toc-modified-id=\"Generate-List-of-Data-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Generate List of Data</a></div><div class=\"lev2 toc-item\"><a href=\"#Construct-Configuration-Matrices\" data-toc-modified-id=\"Construct-Configuration-Matrices-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Construct Configuration Matrices</a></div><div class=\"lev1 toc-item\"><a href=\"#Optimize-Dynamic-Subgraphs\" data-toc-modified-id=\"Optimize-Dynamic-Subgraphs-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Optimize Dynamic Subgraphs</a></div><div class=\"lev2 toc-item\"><a href=\"#Parameter-Search-Space\" data-toc-modified-id=\"Parameter-Search-Space-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Parameter Search Space</a></div><div class=\"lev2 toc-item\"><a href=\"#Run-Non-Negative-Matrix-Factorization-Algorithm\" data-toc-modified-id=\"Run-Non-Negative-Matrix-Factorization-Algorithm-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Run Non-Negative Matrix Factorization Algorithm</a></div><div class=\"lev2 toc-item\"><a href=\"#Analyze-Parameter-Search-Space\" data-toc-modified-id=\"Analyze-Parameter-Search-Space-23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Analyze Parameter Search Space</a></div><div class=\"lev3 toc-item\"><a href=\"#Display-Parameter-Search-Space\" data-toc-modified-id=\"Display-Parameter-Search-Space-231\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Display Parameter Search Space</a></div><div class=\"lev3 toc-item\"><a href=\"#Display-Relationship-Between-Parameters-and-Quality-Measures\" data-toc-modified-id=\"Display-Relationship-Between-Parameters-and-Quality-Measures-232\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Display Relationship Between Parameters and Quality Measures</a></div><div class=\"lev3 toc-item\"><a href=\"#Display-Bivariate-Distribution-of-Error-and-Sparsity\" data-toc-modified-id=\"Display-Bivariate-Distribution-of-Error-and-Sparsity-233\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>Display Bivariate Distribution of Error and Sparsity</a></div><div class=\"lev3 toc-item\"><a href=\"#Find-Optimal-Parameters\" data-toc-modified-id=\"Find-Optimal-Parameters-234\"><span class=\"toc-item-num\">2.3.4&nbsp;&nbsp;</span>Find Optimal Parameters</a></div><div class=\"lev1 toc-item\"><a href=\"#Detect-Dynamic-Subgraphs\" data-toc-modified-id=\"Detect-Dynamic-Subgraphs-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Detect Dynamic Subgraphs</a></div><div class=\"lev2 toc-item\"><a href=\"#Run-Non-Negative-Matrix-Factorization-Algorithm\" data-toc-modified-id=\"Run-Non-Negative-Matrix-Factorization-Algorithm-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Run Non-Negative Matrix Factorization Algorithm</a></div><div class=\"lev2 toc-item\"><a href=\"#Consensus-Clustering-of-Dynamic-Subgraphs\" data-toc-modified-id=\"Consensus-Clustering-of-Dynamic-Subgraphs-32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Consensus Clustering of Dynamic Subgraphs</a></div><div class=\"lev3 toc-item\"><a href=\"#Generate-List-of-Data\" data-toc-modified-id=\"Generate-List-of-Data-321\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Generate List of Data</a></div><div class=\"lev3 toc-item\"><a href=\"#Consensus-Dynamic-Subgraphs\" data-toc-modified-id=\"Consensus-Dynamic-Subgraphs-322\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Consensus Dynamic Subgraphs</a></div><div class=\"lev3 toc-item\"><a href=\"#Plot-Subgraphs\" data-toc-modified-id=\"Plot-Subgraphs-323\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Plot Subgraphs</a></div><div class=\"lev1 toc-item\"><a href=\"#Detect-Geometric-Null-Subgraphs\" data-toc-modified-id=\"Detect-Geometric-Null-Subgraphs-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Detect Geometric-Null Subgraphs</a></div><div class=\"lev2 toc-item\"><a href=\"#Generate-Geometric-Adjacency-Matrix\" data-toc-modified-id=\"Generate-Geometric-Adjacency-Matrix-41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Generate Geometric Adjacency Matrix</a></div><div class=\"lev2 toc-item\"><a href=\"#Run-Non-Negative-Matrix-Factorization-Algorithm\" data-toc-modified-id=\"Run-Non-Negative-Matrix-Factorization-Algorithm-42\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Run Non-Negative Matrix Factorization Algorithm</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    #%reset\n",
    "except:\n",
    "    print 'NOT IPYTHON'\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import scipy.io as io\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "sys.path.append('/Users/akhambhati/Developer/hoth_research/Echobase')\n",
    "import Echobase\n",
    "convert_conn_vec_to_adj_matr = Echobase.Network.Transforms.configuration.convert_conn_vec_to_adj_matr\n",
    "convert_adj_matr_to_cfg_matr = Echobase.Network.Transforms.configuration.convert_adj_matr_to_cfg_matr\n",
    "nmf = Echobase.Network.Partitioning.Subgraph.nmf\n",
    "\n",
    "rcParams = Echobase.Plotting.fig_format.update_rcparams(rcParams)\n",
    "\n",
    "path_CoreData = '/Users/akhambhati/Remotes/CORE.fMRI_multiband.mmattar/restdata'\n",
    "path_PeriphData = '/Users/akhambhati/Remotes/RSRCH.NMF_Subnetworks'\n",
    "path_InpData = path_PeriphData + '/e01-Dyne_FuncNetw'\n",
    "path_ExpData = path_PeriphData + '/e03a-DynFuncSubgraph-Subject'\n",
    "\n",
    "for path in [path_CoreData, path_PeriphData, path_InpData, path_ExpData]:\n",
    "    if not os.path.exists(path):\n",
    "        print('Path: {}, does not exist'.format(path))\n",
    "        os.makedirs(path)\n",
    "\n",
    "if not os.path.exists('./e03a-Figures'):\n",
    "    os.makedirs('./e03a-Figures')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "heading_collapsed": true
   },
   "source": [
    "## Generate List of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "subj_date = [full_subj_path.split('/')[-1]\n",
    "             for full_subj_path in glob.iglob('{}/*.dyne_output.hdf'.format(path_InpData))]\n",
    "\n",
    "subj_ids = {}\n",
    "for s_d in subj_date:\n",
    "    subj, date = s_d.split('.')[:2]\n",
    "    try:\n",
    "        subj_ids[subj]\n",
    "    except KeyError:\n",
    "        subj_ids[subj] = []\n",
    "    \n",
    "    subj_ids[subj].append(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "heading_collapsed": true
   },
   "source": [
    "## Construct Configuration Matrices\n",
    "*__WARNING: Will Delete Existing Output__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Remove all existing output (retains pipe/pipeline definitions)\n",
    "rm_outp = glob.glob(\"{}/*.cfg_matr.npz\".format(path_ExpData))\n",
    "\n",
    "for rm_type in [rm_outp]:\n",
    "    for path in rm_type:\n",
    "        try:\n",
    "            os.remove(path)\n",
    "        except:\n",
    "            print(\"{} not found\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for subj, dates in subj_ids.items():\n",
    "    \n",
    "    cfg_matr = []\n",
    "    for d_i, date in enumerate(dates):\n",
    "        \n",
    "        # Input data paths\n",
    "        log_path = \"{}/{}.{}.dyne_log.csv\".format(path_InpData,\n",
    "                                                  subj, date)\n",
    "        inp_path = \"{}/{}.{}.dyne_output.hdf\".format(path_InpData,\n",
    "                                                     subj, date)\n",
    "\n",
    "        # Read the input data\n",
    "        df_log = pd.read_csv(log_path, delimiter=',')\n",
    "        pipe_hash = df_log[df_log.PIPE_NAME == 'MTCoh'].DOWNSTREAM_HASH[0]\n",
    "        \n",
    "        df_inp = h5py.File(inp_path, 'r')\n",
    "        inp_dat = df_inp[pipe_hash]['data'][...]\n",
    "        inp_meta = df_inp[pipe_hash]['meta']\n",
    "\n",
    "        for cfg_vec in conv_adj_matr_to_cfg_matr(inp_dat):\n",
    "            cfg_matr.append(cfg_vec)\n",
    "                \n",
    "    # Cache the modularity matrices\n",
    "    cfg_matr = np.array(cfg_matr)\n",
    "    np.savez(\"{}/{}.cfg_matr.npz\".format(path_ExpData, subj),\n",
    "             cfg_matr=cfg_matr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Dynamic Subgraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "heading_collapsed": true
   },
   "source": [
    "## Parameter Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Set search ranges\n",
    "search_alpha_log = [0.01, 2.0]\n",
    "search_beta_log = [0.01, 2.0]\n",
    "search_rank = [2, 21]\n",
    "n_search = 30000\n",
    "\n",
    "# Generate parameter set\n",
    "param_set = []\n",
    "param_alpha = np.zeros(n_search)\n",
    "param_beta = np.zeros(n_search)\n",
    "param_rank = np.zeros(n_search)\n",
    "for ii in xrange(n_search):\n",
    "    alpha = np.random.uniform(low=search_alpha_log[0],\n",
    "                              high=search_alpha_log[1])\n",
    "\n",
    "    beta = np.random.uniform(low=search_beta_log[0],\n",
    "                             high=search_beta_log[1])\n",
    "    \n",
    "    rank = np.random.randint(low=search_rank[0],\n",
    "                             high=search_rank[1])\n",
    "    \n",
    "    param_alpha[ii] = alpha\n",
    "    param_beta[ii] = beta\n",
    "    param_rank[ii] = rank\n",
    "    param_set.append({'alpha': alpha,\n",
    "                      'beta': beta,\n",
    "                      'rank': rank})\n",
    "\n",
    "    \n",
    "# Display Joint-Distributions Parameter Space\n",
    "%matplotlib inline\n",
    "g = sns.jointplot(param_alpha, param_beta, kind='kde')\n",
    "g.set_axis_labels('Alpha', 'Beta')\n",
    "\n",
    "g = sns.jointplot(param_alpha, param_rank, kind='kde')\n",
    "g.set_axis_labels('Alpha', 'Rank')\n",
    "\n",
    "g = sns.jointplot(param_beta, param_rank, kind='kde')\n",
    "g.set_axis_labels('Beta', 'Rank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "heading_collapsed": true
   },
   "source": [
    "## Run Non-Negative Matrix Factorization Algorithm\n",
    "*__WARNING: Will Delete Existing Output__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Remove all existing output (retains pipe/pipeline definitions)\n",
    "rm_outp = glob.glob(\"{}/subgraph_param_opt-*.npz\".format(path_ExpData))\n",
    "\n",
    "for rm_type in [rm_outp]:\n",
    "    for path in rm_type:\n",
    "        try:\n",
    "            os.remove(path)\n",
    "        except:\n",
    "            print(\"{} not found\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "parallel_run = True\n",
    "\n",
    "# Associate param search with a randomly chosen subject\n",
    "subj_cfgmatr_path = glob.glob(\"{}/*.cfg_matr.npz\".format(path_ExpData))\n",
    "proc_list = []\n",
    "for ii, param in enumerate(param_set):\n",
    "    path = np.random.permutation(subj_cfgmatr_path)[0]\n",
    "    proc_list.append((ii+1, param, path))\n",
    "    \n",
    "# Setup helper function to map pipeline run\n",
    "def _nmf_helper(proc_item):\n",
    "    ii, param, inp_path = proc_item\n",
    "    \n",
    "    # Load the file\n",
    "    #if os.path.exists(inp_path):\n",
    "    #    return 0\n",
    "    print(\" -- Processing: {}, with Parameter: {}\".format(inp_path.split('/')[-1],\n",
    "                                                          ii))\n",
    "    data = np.load(inp_path, mmap_mode='r')\n",
    "    \n",
    "    # Initialize the factors for NMF\n",
    "    fac_subnet = np.random.uniform(low=0, high=1.0,\n",
    "                                   size=(param['rank'],\n",
    "                                         data['cfg_matr'].shape[1]))\n",
    "    fac_coef = np.random.uniform(low=0, high=1.0,\n",
    "                                 size=(param['rank'],\n",
    "                                       data['cfg_matr'].shape[0]))\n",
    "\n",
    "    # Run NMF Algorithm\n",
    "    fac_subnet, fac_coef, err = nmf.snmf_bcd(\n",
    "        data['cfg_matr'],\n",
    "        alpha=param['alpha'], beta=param['beta'],\n",
    "        fac_subnet_init=fac_subnet,\n",
    "        fac_coef_init=fac_coef,\n",
    "        max_iter=100, verbose=False)\n",
    "    \n",
    "    # Cache the NMF result\n",
    "    np.savez(\"{}/subgraph_param_opt-{}.npz\".format(path_ExpData, ii),\n",
    "             fac_subnet=fac_subnet, fac_coef=fac_coef, err=err,\n",
    "             param=param, path=path)\n",
    "\n",
    "if parallel_run:\n",
    "    mp = Pool(7)\n",
    "    mp.map(_nmf_helper, proc_list)\n",
    "else:\n",
    "    map(_nmf_helper, proc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Analyze Parameter Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "param_run = glob.glob(\"{}/subgraph_param_opt-*.npz\".format(path_ExpData))\n",
    "n_param = len(param_run)\n",
    "\n",
    "param_alpha = np.zeros(n_param)\n",
    "param_beta = np.zeros(n_param)\n",
    "param_rank = np.zeros(n_param)\n",
    "\n",
    "err = np.zeros(n_param)\n",
    "subnet_sparsity = np.zeros(n_param)\n",
    "coef_sparsity = np.zeros(n_param)\n",
    "\n",
    "ii = 0\n",
    "for path in param_run:\n",
    "    data = np.load(path, mmap_mode='r')\n",
    "    param = data['param'][()]\n",
    "    \n",
    "    param_alpha[ii] = param['alpha']\n",
    "    param_beta[ii] = param['beta']\n",
    "    param_rank[ii] = param['rank']\n",
    "\n",
    "    err[ii] = data['err'][-1]\n",
    "    subnet_sparsity[ii] = (data['fac_subnet'] == 0).mean()\n",
    "    coef_sparsity[ii] = (data['fac_coef'] == 0).mean()\n",
    "    \n",
    "    ii += 1\n",
    "\n",
    "param_alpha = param_alpha[:ii]\n",
    "param_beta = param_beta[:ii]\n",
    "param_rank = param_rank[:ii]\n",
    "\n",
    "err = err[:ii]\n",
    "subnet_sparsity = subnet_sparsity[:ii]\n",
    "coef_sparsity = coef_sparsity[:ii]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Display Parameter Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "plt.figure()                \n",
    "ax = plt.subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(param_alpha, param_beta, param_rank, alpha=0.3, color='k', s=1.0)\n",
    "\n",
    "ax.set_xlabel('Alpha')\n",
    "ax.set_ylabel('Beta')\n",
    "ax.set_zlabel('Rank')\n",
    "\n",
    "plt.savefig('./e03-Figures/Parameter_Search_Space.svg')                           \n",
    "plt.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Display Relationship Between Parameters and Quality Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "for qmeas, qname in [(err, 'Residual Error'),\n",
    "                     (subnet_sparsity, 'Pct Subgraph Sparse'),\n",
    "                     (coef_sparsity, 'Pct Coef Sparse')]:\n",
    "    print('Plotting -- {}'.format(qname))\n",
    "    \n",
    "    plt.figure()                \n",
    "    g = sns.jointplot(param_rank, qmeas, kind='kde',\n",
    "                       ylim=[np.min(qmeas), np.max(qmeas)])\n",
    "    g.set_axis_labels('Rank', qname)\n",
    "    plt.savefig('./e03-Figures/Param_{}-QMeas_{}.svg'.format('rank', qname))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    g = sns.jointplot((param_alpha), qmeas, kind='kde',\n",
    "                       ylim=[np.min(qmeas), np.max(qmeas)])\n",
    "    g.set_axis_labels('Alpha', qname)\n",
    "    plt.savefig('./e03-Figures/Param_{}-QMeas_{}.svg'.format('alpha', qname))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    g = sns.jointplot((param_beta), qmeas, kind='kde',\n",
    "                       ylim=[np.min(qmeas), np.max(qmeas)])\n",
    "    g.set_axis_labels('Beta', qname)\n",
    "    plt.savefig('./e03-Figures/Param_{}-QMeas_{}.svg'.format('beta', qname))\n",
    "    plt.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Display Bivariate Distribution of Error and Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "g = sns.jointplot(subnet_sparsity, err, kind='kde',\n",
    "                  xlim=[np.min(subnet_sparsity), np.max(subnet_sparsity)],\n",
    "                  ylim=[np.min(err), np.max(err)])\n",
    "g.set_axis_labels('Pct Subgraph Sparse', 'Residual Error')\n",
    "plt.savefig('./e03-Figures/QMeas_{}-QMeas_{}.svg'.format('Pct Subgraph Sparse', 'Residual Error'))\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "g = sns.jointplot(coef_sparsity, err, kind='kde',\n",
    "                  xlim=[np.min(coef_sparsity), np.max(coef_sparsity)],\n",
    "                  ylim=[np.min(err), np.max(err)])\n",
    "g.set_axis_labels('Pct Coef Sparse', 'Residual Error')\n",
    "plt.savefig('./e03-Figures/QMeas_{}-QMeas_{}.svg'.format('Pct Coef Sparse', 'Residual Error'))\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "g = sns.jointplot(subnet_sparsity, coef_sparsity, kind='kde',\n",
    "                  xlim=[np.min(subnet_sparsity), np.max(subnet_sparsity)],\n",
    "                  ylim=[np.min(coef_sparsity), np.max(coef_sparsity)])\n",
    "g.set_axis_labels('Pct Subgraph Sparse', 'Pct Coef Sparse')\n",
    "plt.savefig('./e03-Figures/QMeas_{}-QMeas_{}.svg'.format('Pct Subgraph Sparse', 'Pct Coef Sparse'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "heading_collapsed": true
   },
   "source": [
    "### Find Optimal Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Minimize the residual error and maximize subgraph and temporal coefficient sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Specify ranges\n",
    "err_range = [np.percentile(err, 0), np.percentile(err, 25)]\n",
    "subnet_sparsity_range = [np.percentile(subnet_sparsity, 75), np.percentile(subnet_sparsity, 100)]\n",
    "coef_sparsity_range = [np.percentile(coef_sparsity, 75), np.percentile(coef_sparsity, 100)]\n",
    "\n",
    "err_ix = np.flatnonzero((err >= err_range[0]) & (err <= err_range[1]))\n",
    "subnet_sparsity_ix = np.flatnonzero((subnet_sparsity >= subnet_sparsity_range[0]) &\n",
    "                                    (subnet_sparsity <= subnet_sparsity_range[1]))\n",
    "coef_sparsity_ix = np.flatnonzero((coef_sparsity >= coef_sparsity_range[0]) &\n",
    "                                    (coef_sparsity <= coef_sparsity_range[1]))\n",
    "\n",
    "param_ix = np.intersect1d(np.intersect1d(err_ix, subnet_sparsity_ix), coef_sparsity_ix)\n",
    "n_param = len(param_ix)\n",
    "\n",
    "print('Alpha: {} +/- {}'.format(np.mean(param_alpha[param_ix]),\n",
    "                                np.std(param_alpha[param_ix]) / np.sqrt(n_param)))\n",
    "print('Beta: {} +/- {}'.format(np.mean(param_beta[param_ix]),\n",
    "                               np.std(param_beta[param_ix]) / np.sqrt(n_param)))\n",
    "print('Rank: {} +/- {}'.format(np.mean(param_rank[param_ix]),\n",
    "                               np.std(param_rank[param_ix]) / np.sqrt(n_param)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "heading_collapsed": true
   },
   "source": [
    "# Detect Dynamic Subgraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Run Non-Negative Matrix Factorization Algorithm\n",
    "*__WARNING: Will Delete Existing Output__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Remove all existing output (retains pipe/pipeline definitions)\n",
    "rm_outp = glob.glob(\"{}/*.subgraph_seed-*.npz\".format(path_ExpData))\n",
    "\n",
    "for rm_type in [rm_outp]:\n",
    "    for path in rm_type:\n",
    "        try:\n",
    "            os.remove(path)\n",
    "        except:\n",
    "            print(\"{} not found\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "param = {'rank': 16,\n",
    "         'alpha': 1.37,\n",
    "         'beta': 1.38}\n",
    "n_seed = 100\n",
    "\n",
    "from multiprocessing import Pool\n",
    "parallel_run = True\n",
    "\n",
    "# Generate a processing joblist\n",
    "subj_cfgmatr_path = glob.glob(\"{}/*.cfg_matr.npz\".format(path_ExpData))\n",
    "proc_list = []\n",
    "for seed in xrange(n_seed):\n",
    "    for path in subj_cfgmatr_path:\n",
    "        subj_name = path.split('/')[-1].split('.')[0]\n",
    "        proc_list.append({'subj_name': subj_name,\n",
    "                          'path': path,\n",
    "                          'param': param,\n",
    "                          'seed': seed+1})\n",
    "    \n",
    "# Setup helper function to map pipeline run\n",
    "def _nmf_helper(proc_item):\n",
    "    \n",
    "    # Load the file\n",
    "    #if os.path.exists(inp_path):\n",
    "    #    return 0\n",
    "    print(\" -- Processing: {}, with Parameter: {}\".format(proc_item['subj_name'],\n",
    "                                                          proc_item['seed']))\n",
    "    data = np.load(proc_item['path'], mmap_mode='r')\n",
    "    \n",
    "    # Initialize the factors for NMF\n",
    "    fac_subnet = np.random.uniform(low=0, high=1.0,\n",
    "                                   size=(proc_item['param']['rank'],\n",
    "                                         data['cfg_matr'].shape[1]))\n",
    "    fac_coef = np.random.uniform(low=0, high=1.0,\n",
    "                                 size=(proc_item['param']['rank'],\n",
    "                                       data['cfg_matr'].shape[0]))\n",
    "\n",
    "    # Run NMF Algorithm\n",
    "    fac_subnet, fac_coef, err = nmf.snmf_bcd(\n",
    "        data['cfg_matr'],\n",
    "        alpha=proc_item['param']['alpha'],\n",
    "        beta=proc_item['param']['beta'],\n",
    "        fac_subnet_init=fac_subnet,\n",
    "        fac_coef_init=fac_coef,\n",
    "        max_iter=100, verbose=False)\n",
    "    \n",
    "    # Cache the NMF result\n",
    "    np.savez(\"{}/{}.subgraph_seed-{}.npz\".format(path_ExpData,\n",
    "                                                 proc_item['subj_name'],\n",
    "                                                 proc_item['seed']),\n",
    "             fac_subnet=fac_subnet, fac_coef=fac_coef, err=err,\n",
    "             param=proc_item['param'], path=proc_item['path'])\n",
    "\n",
    "if parallel_run:\n",
    "    mp = Pool(7)\n",
    "    mp.map(_nmf_helper, proc_list)\n",
    "else:\n",
    "    map(_nmf_helper, proc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Consensus Clustering of Dynamic Subgraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Generate List of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "subj_ids = np.unique([full_subj_path.split('/')[-1].split('.')[0]\n",
    "                      for full_subj_path in glob.iglob('{}/*.subgraph_seed-*.npz'.format(path_ExpData))])\n",
    "\n",
    "subj_seeds = {}\n",
    "for subj in subj_ids:\n",
    "    subj_seeds[subj] = {'seed_path': [full_subj_path\n",
    "                                      for full_subj_path in glob.iglob('{}/{}.subgraph_seed-*.npz'.format(path_ExpData, subj))],\n",
    "                        'cfg_path': '{}/{}.cfg_matr.npz'.format(path_ExpData, subj)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Consensus Dynamic Subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for ii, (subj, paths) in enumerate(subj_seeds.items()):\n",
    "    print(\" -- Processing: {}\".format(subj))\n",
    "    \n",
    "    fac_subnet_seeds = []\n",
    "    for ix, path in enumerate(paths['seed_path']):\n",
    "        data = np.load(path, mmap_mode='r')\n",
    "        fac_subnet = data['fac_subnet'][:, :]\n",
    "        data.close()\n",
    "        \n",
    "        n_fac = fac_subnet.shape[0]\n",
    "        n_conn = fac_subnet.shape[1]\n",
    "\n",
    "        for ix in xrange(fac_subnet.shape[0]):\n",
    "            fac_subnet_seeds.append(fac_subnet[ix, :])\n",
    "    fac_subnet_seeds = np.array(fac_subnet_seeds)\n",
    "    \n",
    "    n_obs = fac_subnet_seeds.shape[0]\n",
    "    n_conn = fac_subnet_seeds.shape[1]\n",
    "\n",
    "    # Consensus Subgraphs\n",
    "    fac_cons_subnet, fac_cons_seeds, err = nmf.snmf_bcd(\n",
    "        fac_subnet_seeds,\n",
    "        alpha=0.0,\n",
    "        beta=0.0,\n",
    "        fac_subnet_init=np.random.uniform(low=0.0, high=1.0, size=(n_fac, n_conn)),\n",
    "        fac_coef_init=np.random.uniform(low=0.0, high=1.0, size=(n_fac, n_obs)),\n",
    "        max_iter=100, verbose=False)\n",
    "    \n",
    "    # Consensus Coefficients\n",
    "    data_cfg = np.load(paths['cfg_path'], mmap_mode='r')\n",
    "    n_win = data_cfg['cfg_matr'].shape[0]\n",
    "    fac_cons_subnet_2, fac_cons_coef_2, err = nmf.snmf_bcd(\n",
    "        data_cfg['cfg_matr'],\n",
    "        alpha=0.0,\n",
    "        beta=0.0,\n",
    "        fac_subnet_init=fac_cons_subnet,\n",
    "        fac_coef_init=np.random.uniform(low=0.0, high=1.0, size=(n_fac, n_win)),\n",
    "        max_iter=100, verbose=False)\n",
    "    \n",
    "    # Cache the Consensus NMF result\n",
    "    np.savez(\"{}/{}.consensus_subgraph.npz\".format(path_ExpData,\n",
    "                                                   subj),\n",
    "             fac_subnet=fac_cons_subnet_2, fac_coef=fac_cons_coef_2, err=err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "for ss in subj_ids:\n",
    "    data = np.load(\"{}/{}.consensus_subgraph.npz\".format(path_ExpData, ss),\n",
    "                   mmap_mode='r')\n",
    "    fac_subnet = data['fac_subnet']\n",
    "    fac_coef = data['fac_coef']\n",
    "\n",
    "    n_fac = fac_subnet.shape[0]\n",
    "    n_conn = fac_subnet.shape[1]\n",
    "    n_win = fac_coef.shape[1]\n",
    "    \n",
    "    # Plot subgraph matrix\n",
    "    plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    mat = ax.matshow(fac_subnet.T, aspect=n_fac/n_conn, cmap='rainbow')\n",
    "    plt.colorbar(mat, ax=ax)\n",
    "    \n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    #ax.set_xticks(np.linspace(0, 80, 5))\n",
    "    ax.set_ylabel('Functional Interactions')\n",
    "    ax.set_xlabel('Subgraphs')\n",
    "\n",
    "    plt.savefig('./e03a-Figures/{}-Subgraph-Cfg_Matrix.svg'.format(ss))\n",
    "    plt.close()      \n",
    "    \n",
    "    # Plot subgraph adjacency\n",
    "    for ii, subg in enumerate(fac_subnet):\n",
    "        adj = convert_conn_vec_to_adj_matr(subg)\n",
    "        \n",
    "        plt.figure()\n",
    "        ax = plt.subplot(111)\n",
    "        mat = ax.matshow(adj, cmap='rainbow')\n",
    "        plt.colorbar(mat, ax=ax)\n",
    "        \n",
    "        ax.yaxis.set_ticks_position('left')\n",
    "        ax.xaxis.set_ticks_position('bottom')\n",
    "        ax.set_ylabel('Brain Regions')\n",
    "        ax.set_xlabel('Brain Regions')\n",
    "\n",
    "        plt.savefig('./e03a-Figures/{}-Subgraph-Adj-{}.svg'.format(ss, ii+1))\n",
    "        plt.close()      \n",
    "\n",
    "    # Plot Coefficients\n",
    "    plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    fac_coef = fac_coef.T\n",
    "    norm_fac = fac_coef - fac_coef.mean(axis=0)\n",
    "    for ff in xrange(n_fac):\n",
    "        ax.plot(ff + norm_fac[:, ff] / (3*np.std(norm_fac[:, ff])), color=[66/256., 152/256., 221./256])\n",
    "\n",
    "    # Axis Settings\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_ylim([-1, n_fac+1])\n",
    "    ax.set_ylabel('Subgraphs')\n",
    "    ax.set_xlabel('Time Windows')\n",
    "\n",
    "    plt.savefig('./e03a-Figures/{}-Subgraph-Coefs.svg'.format(ss))\n",
    "    plt.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect Geometric-Null Subgraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Geometric Adjacency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate Node Distance Matrix\n",
    "df = pd.read_csv('{}/Atlas/HOA112_Labels.csv'.format(path_CoreData))\n",
    "n_node = len(df)\n",
    "\n",
    "dist_matr = np.zeros((n_node, n_node))\n",
    "ix, iy = np.mgrid[:n_node, :n_node]\n",
    "\n",
    "dX = np.array(df.X)\n",
    "dY = np.array(df.Y)\n",
    "dZ = np.array(df.Z)\n",
    "\n",
    "dist_matr[ix, iy] = np.sqrt((dX[ix]-dX[iy])**2 + \n",
    "                            (dY[ix]-dY[iy])**2 +\n",
    "                            (dZ[ix]-dZ[iy])**2)\n",
    "dist_matr /= dist_matr.max()\n",
    "\n",
    "np.savez('{}/geom_adj_matr.npz'.format(path_ExpData),\n",
    "         dist_matr=dist_matr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Non-Negative Matrix Factorization Algorithm\n",
    "*__WARNING: Will Delete Existing Output__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove all existing output (retains pipe/pipeline definitions)\n",
    "rm_outp = glob.glob(\"{}/*.GeomNull.subgraph_seed-*.npz\".format(path_ExpData))\n",
    "\n",
    "for rm_type in [rm_outp]:\n",
    "    for path in rm_type:\n",
    "        try:\n",
    "            os.remove(path)\n",
    "        except:\n",
    "            print(\"{} not found\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param = {'rank': 16,\n",
    "         'alpha': 1.37,\n",
    "         'beta': 1.38}\n",
    "n_seed = 100\n",
    "\n",
    "from multiprocessing import Pool\n",
    "parallel_run = True\n",
    "\n",
    "# Generate a processing joblist\n",
    "subj_cfgmatr_path = glob.glob(\"{}/*.cfg_matr.npz\".format(path_ExpData))\n",
    "proc_list = []\n",
    "for seed in xrange(n_seed):\n",
    "    for path in subj_cfgmatr_path:\n",
    "        subj_name = path.split('/')[-1].split('.')[0]\n",
    "        proc_list.append({'subj_name': subj_name,\n",
    "                          'path': path,\n",
    "                          'param': param,\n",
    "                          'seed': seed+1\n",
    "                          'dist_path': '{}/geom_adj_matr.npz'.format(path_ExpData)})\n",
    "    \n",
    "# Setup helper function to map pipeline run\n",
    "def _nmf_helper(proc_item):\n",
    "    \n",
    "    # Load the file\n",
    "    #if os.path.exists(inp_path):\n",
    "    #    return 0\n",
    "    print(\" -- Processing: {}, with Parameter: {}\".format(proc_item['subj_name'],\n",
    "                                                          proc_item['seed']))\n",
    "    data = np.load(proc_item['path'], mmap_mode='r')\n",
    "    dist_matr = np.load(proc_item['dist_path'])['dist_matr']\n",
    "    \n",
    "    # Generate a geometric null topology from cfg_matr\n",
    "    cfg_matr_null = []\n",
    "    for cfg_vec in data['cfg_matr']:\n",
    "        adj_matr = convert_conn_vec_to_adj_matr(cfg_vec)\n",
    "        adj_null = Echobase.Network.Rewire.geometry.surrogate_trend(adj_matr, dist_matr, 3, 3)\n",
    "        cfg_matr_null.append(convert_adj_matr_to_cfg_matr(np.expand_dims(adj_null, axis=0)).reshape(-1))\n",
    "    cfg_matr_null = np.array(cfg_matr_null)\n",
    "    \n",
    "    # Initialize the factors for NMF\n",
    "    fac_subnet = np.random.uniform(low=0, high=1.0,\n",
    "                                   size=(proc_item['param']['rank'],\n",
    "                                         cfg_matr_null.shape[1]))\n",
    "    fac_coef = np.random.uniform(low=0, high=1.0,\n",
    "                                 size=(proc_item['param']['rank'],\n",
    "                                       cfg_matr_null.shape[0]))\n",
    "\n",
    "    # Run NMF Algorithm\n",
    "    fac_subnet, fac_coef, err = nmf.snmf_bcd(\n",
    "        cfg_matr_null,\n",
    "        alpha=proc_item['param']['alpha'],\n",
    "        beta=proc_item['param']['beta'],\n",
    "        fac_subnet_init=fac_subnet,\n",
    "        fac_coef_init=fac_coef,\n",
    "        max_iter=100, verbose=False)\n",
    "    \n",
    "    # Cache the NMF result\n",
    "    np.savez(\"{}/{}.GeomNull.subgraph_seed-{}.npz\".format(path_ExpData,\n",
    "                                                          proc_item['subj_name'],\n",
    "                                                          proc_item['seed']),\n",
    "             fac_subnet=fac_subnet, fac_coef=fac_coef, err=err,\n",
    "             param=proc_item['param'], path=proc_item['path'])\n",
    "\n",
    "if parallel_run:\n",
    "    mp = Pool(7)\n",
    "    mp.map(_nmf_helper, proc_list)\n",
    "else:\n",
    "    map(_nmf_helper, proc_list)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0,
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "372px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_position": {
    "height": "853px",
    "left": "0px",
    "right": "1576px",
    "top": "106px",
    "width": "343px"
   },
   "toc_section_display": "block",
   "toc_threshold": 6,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
